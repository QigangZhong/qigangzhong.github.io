---
layout: post
title:  "rabbitmq"
categories: tools
tags:  kafka
author: 网络
---

* content
{:toc}

总结kafka的安装及使用方法







## 概念

![kafka_broker_partition.png](/images/mq/kafka_broker_partition.png)

* broker

就是一个机器节点

* partition

Kafka的消息通过topic进行分类。topic可以被分为N个partition来存储消息（每个partition只会落在一个broker上，不会跨broker）。消息以追加的方式写入partition，然后以先入先出的顺序读取。

通过命令创建topic的时候可以设置`-partitions 1`参数来指定topic的消息分别存储到几个分区上，如果不指定，则使用broker配置`config/server.properties`中配置的`num.partitions=1`。topic的消息分发到partition上默认是通过hash来进行分区的，每个partition存储的数据是不同的。

partition磁盘文件的名称是logs目录下的以TOPIC_NAME-n命名的目录，例如`demo-topic-0`，目录下面是成对的xxx.index（记录消息偏移量等元数据），xxx.log（消息体本身），这一对文件称为segment file。

![kafka_segment-file.png](/images/mq/kafka_segment-file.png)

每个partition内部消息是有序的，但是多个partition无法保证消息的顺序。partition中的消息都有一个序号叫offset标记消息的位置。

topic的分区被分配在不同broker上，不同的broker上的partition组成topic的分区副本列表，其中有一个副本是leader，负责数据读写，其它分区作为备份。

每一个消息分区，只能被同组的一个消费者消费

* producer

producer可以指定数据有几个分区（partition）、几个备份（broker）。producer只关联broker集群中的一个broker进行数据发送。

* consumer

* consumer group

每条消息只发送给分组中的一个consumer，不同的消费者分组消费自己特定的Topic下面的消息，互不干扰。

topic下的每个分区只能分配给某个group下的一个consumer(当然该分区还可以被分配给其他group)

## 安装

### centos7上安装JDK8

已安装忽略此步骤

1.卸载centos原本自带的openjdk（直接使用openjdk也是可以的，只是缺少部分开发功能）

```bash
# 首先查找jdk安装包
rpm -qa | grep java

# 执行删除命令
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
rpm -e --nodeps java-xxxxxx
```

2.从[JDK下载地址](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)下载[tar.gz](https://download.oracle.com/otn/java/jdk/8u221-b11/230deb18db3e4014bb8e3e8324f81b43/jdk-8u221-linux-x64.tar.gz)安装包

```bash
# 创建目录，用来放jdk安装文件
mkdir -p /usr/local/jdk
cd /usr/local/jdk
# 将tar.gz包放进来，然后执行解压
tar -zxvf jdk-8u221-linux-x64.tar.gz
cd jdk1.8.0_221
```

3.添加环境变量

```bash
vim /etc/profile
-------------------------------------------------------------------------------------------
export JAVA_HOME=/usr/local/jdk/jdk1.8.0_221
export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$PATH:$JAVA_HOME/bin
-------------------------------------------------------------------------------------------
source /etc/profile

# 查看版本，确保安装成功
java -version
```

### [安装zookeeper](https://qigangzhong.github.io/2019/05/20/zookeeper/#%E4%B8%80%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE)

安装好后启动zk服务器

### 安装kafka

[下载地址](http://kafka.apache.org/downloads)，下载0.11.0.3版本的tgz包

```bash
mkdir /usr/local/kafka
cd /usr/local/kafka/
# 将tgz包放进来并解压
tar -zxvf kafka_2.11-0.11.0.3.tgz
# 修改配置文件
cd kafka_2.11-0.11.0.3/config/
vim server.properties
------------------------------------------------------
broker.id=0
listeners=PLAINTEXT://内网ip:9092
advertised.listeners=PLAINTEXT://服务器外网ip:9092
log.dirs=/usr/local/kafka/kafka_2.11-0.11.0.3/logs
zookeeper.connect=localhost:2181
------------------------------------------------------

# 配置环境变量
vim /etc/profile
------------------------------------------------------
export KAFKA_HOME=/usr/local/kafka/kafka_2.11-0.11.0.3
export PATH=$PATH:$KAFKA_HOME/bin
------------------------------------------------------
source /etc/profile
```

### 启动kafka

```bash
cd /usr/local/kafka/kafka_2.11-0.11.0.3
# 启动
sh ./bin/kafka-server-start.sh ./config/server.properties
# jps查看进程
# 停止
sh ./bin/kafka-server-stop.sh ./config/server.properties
# 查看zk里面broker的配置信息
zookeeper-shell.sh localhost:2181 <<< "get /brokers/ids/0"

# 创建一个测试topic
# replication-factor：消息保存在几个broker上，一般等于broker数量
# partitions：有几个分区，分区数量应该<=broker数量
# 也可以指定--replica-assignment 0:1,1:2,2:0（表示0、1、2三个分区，分别分布在3个broker上面）
kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic Hello-Kafka
# 查看topic列表
kafka-topics.sh --list --zookeeper localhost:2181
# 查看topic的分区信息
kafka-topics.sh --describe --zookeeper localhost:2181 --topic Hello-Kafka
# 修改topic的partition数量（分区数量只能增加不能减少）
# 修改partition也可以通过kafka-reassign-partitions.sh脚本指定json文件来修改：http://kafka.apache.org/documentation/#basic_ops_increase_replication_factor
kafka-topics.sh --zookeeper localhost:2181 --alter --topic Hello-Kafka --partitions 2
# 查看topic分区信息
kafka-topics.sh --zookeeper localhost:2181 --describe --topic Hello-Kafka

# 启动生产者客户端，发送消息
kafka-console-producer.sh --broker-list localhost:9092 --topic Hello-Kafka
# 启动消费者客户端，接收消息
kafka-console-consumer.sh --zookeeper localhost:2181 -topic Hello-Kafka

# 删除topic（配置中delete.topic.enable=true则）
kafka-topics.sh --zookeeper localhost:2181 --delete --topic Hello-Kafka
```

#### 彻底删除topic

```bash
# 1.停止producer以及consumer应用程序
# 2.server.properties设置
delete.topic.enable=true
# 3.执行删除topic命令
kafka-topics.sh --zookeeper localhost:2181 --delete --topic Hello-Kafka
# 4.删除server.properties配置中`log.dirs`对应的目录
# 5.zk上执行删除命令
zkCli.sh -server localhost:2181
rmr /brokers/topics/TOPIC_NAME
rmr /admin/delete_topics/TOPIC_NAME
rmr /consumers/CONSUMER_GROUP
rmr /config/topics/TOPIC_NAME
# 6.查看topic列表
kafka-topics.sh --list --zookeeper localhost:2181
```

### 单机多broker集群（伪集群）

在一个机器上启动多个broker，只需要配置文件复制多个，broker.id、端口、日志目录配置修改一下，启动时指定不同的配置文件即可

```bash
/usr/local/kafka/kafka_2.11-0.11.0.3/config
cp server.properties server-1.properties
cp server.properties server-2.properties

vim server-1.properties
------------------------------------------------------
broker.id=1
port=9093
log.dirs=/usr/local/kafka/kafka_2.11-0.11.0.3/logs-1
------------------------------------------------------
vim server-2.properties
------------------------------------------------------
broker.id=2
port=9094
log.dirs=/usr/local/kafka/kafka_2.11-0.11.0.3/logs-2
------------------------------------------------------

# 启动3个broker
sh ./bin/kafka-server-start.sh ./config/server.properties
sh ./bin/kafka-server-start.sh ./config/server-1.properties
sh ./bin/kafka-server-start.sh ./config/server-2.properties


#如果想后台运行kafka，可以使用nohup命令（启动日志的目录logs、logs-1、logs-2需要手动创建一下）
nohup sh ./bin/kafka-server-start.sh ./config/server.properties >> ./logs/start.log 2>&1 &
nohup sh ./bin/kafka-server-start.sh ./config/server-1.properties >> ./logs-1/start.log 2>&1 &
nohup sh ./bin/kafka-server-start.sh ./config/server-2.properties >> ./logs-2/start.log 2>&1 &
```

测试集群

```bash
# 启动一个consumer
kafka-console-consumer.sh --zookeeper localhost:2181 -topic Hello-Kafka

# 启动3个producer发送消息到3个broker，会发现consumer可以收到所有的消息
kafka-console-producer.sh --broker-list localhost:9092 --topic Hello-Kafka
kafka-console-producer.sh --broker-list localhost:9093 --topic Hello-Kafka
kafka-console-producer.sh --broker-list localhost:9094 --topic Hello-Kafka
```

集群操作

```bash
# 创建topic，指定保存在3个broker上，这样在logs、logs-1、logs-2三个文件夹下面都会出现一个名称为multi-broker-topic-0的partition目录
sh ./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 -partitions 1 --topic multi-broker-topic

# 查看topic信息
# 根据下面打印的信息可以知道，multi-broker-topic有一个分区，数据分布在3个broker上，这个分区编号是0（多个partition会有多行记录，编号递增），起作用的broker.id=2（leader编号），有3个副本（2,0,1开头的编号是起作用的broker.id）
sh ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic multi-broker-topic
----------------------------------------------------------------------------------------
Topic:multi-broker-topic	PartitionCount:1	ReplicationFactor:3	Configs:
	Topic: multi-broker-topic	Partition: 0	Leader: 2	Replicas: 2,0,1	Isr: 2,0,1
----------------------------------------------------------------------------------------

# 启动producer，发送消息
kafka-console-producer.sh --broker-list localhost:9092 --topic multi-broker-topic
# 启动consumer，接收消息
kafka-console-consumer.sh --zookeeper localhost:2181 -topic multi-broker-topic
```

> `kafka-topics.sh --describe`命令查看的信息字段解释：
>
> * PartitionCount：partition 个数
> * ReplicationFactor：副本个数
> * Partition：partition 编号，从 0 开始递增
> * Leader：当前 partition 起作用的 broker.id
> * Replicas: 当前副本数据所在的 broker.id，是一个列表，排在最前面的起作用
> * Isr：当前 kakfa 集群中可用的 broker.id 列表

### 多机多broker集群

方法同单机多broker集群类似，需要注意的是broker.id区分开来，并且zk的地址配置成一样

## 集成springboot

## 常见mq对比

|                                                                                                            | Kafka                                                                          | RabbitMQ                                                             | ActiveMQ                                             |
| ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------- | ---------------------------------------------------- |
| 消息回溯                                                                                               | 支持，无论是否被消费都会保留，可设置策略进行过滤删除（基于消息超时或消息大小） | 不支持，一旦被确认消费就会标记删除                  | 不支持                                            |
| API完备性                                                                                               | 高                                                                            | 高                                                                  | 中                                                  |
| 单机吞吐量                                                                                            | 十万级                                                                      | 万级                                                               | 万级                                               |
| 首次部署难度                                                                                         | 中                                                                            | 低                                                                  | 低                                                  |
| 消息堆积                                                                                               | 支持                                                                         | 支持（内存堆积达到特定阈值可能会影响性能）      | 支持（有上线，当消息过期或存储设备溢出时，会终结它） |
| 消息持久化（数据持久化到硬盘）                                                              | 支持                                                                         | 支持                                                               | 不支持                                            |
| 多语言支持                                                                                            | 支持，Java优先                                                            | 语言无关                                                         | 支持，Java优先                                  |
| 消息优先级设置（某些消息被优先处理）                                                     | 不支持                                                                      | 支持                                                               | 支持                                               |
| 消息延迟（消息被发送之后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费） | 不支持                                                                      | 支持                                                               | 支持                                               |
| 消费模式（①推模式：由消息中间件主动地将消息推送给消费者；②拉模式：由消费者主动向消息中间件拉取消息） | 拉模式                                                                      | 推模式+拉模式                                                  | 推模式+拉模式                                  |
| 消息追溯                                                                                               | 不支持                                                                      | 支持（有插件，可进行界面管理）                        | 支持（可进行界面管理）                    |
| 常用场景                                                                                               | 日志处理、大数据等                                                    | 金融支持机构                                                   | 降低服务之间的耦合                          |
| 运维管理                                                                                               | 有多种插件可进行监控，如Kafka Management                           | 有多种插件可进行监控，如rabbitmq_management(不利于做二次开发和维护） | 无                                                  |
{: .table.table-bordered }

## 其它

* zookeeper的作用

![kafka_zookeeper_structure.png](/images/mq/kafka_zookeeper_structure.png)

broker注册`/brokers/ids`

topic注册`/borkers/topics`

consumer注册及负载均衡`/consumers/[group_id]/ids/[consumer_id]`存储该消费者订阅的topic信息，监听其它consumer注册事件，监听broker的注册事件

记录consumer和partition关系，`/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]`节点对应的内容是consumer_id

记录consumer消费消息的进度offset值，`/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]`节点内容就是offset值

* 自定义分区规则partitioner.class
* consumer group
* 消息的顺序消费

消息总是持久化的，消息被消费之后不会立即删除，会根据配置中的时间（默认7天），到期之后才删除，不管消息是否被消费过

## 参考

[kafka documentation](http://kafka.apache.org/documentation/#gettingStarted)

[Kafka的Topic和Partition](https://blog.csdn.net/lrxcmwy2/article/details/82853300)

[Kafka学习笔记：常见消息队列对比分析](https://blog.csdn.net/lrxcmwy2/article/details/82846417)

[Kafka命令行工具](https://blog.csdn.net/lrxcmwy2/article/details/82983494)

[***理解 Kafka 中的 Topic 和 Partition](https://blog.csdn.net/Dongguabai/article/details/86536894)

[How to choose the number of topics/partitions in a Kafka cluster?](https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster)

[Kafka Producer配置解读](https://atbug.com/kafka-producer-config/)

[@KafkaListener的花式操作](https://www.jianshu.com/p/a64defb44a23)

[Zookeeper 在 Kafka 中的作用](https://www.jianshu.com/p/a036405f989c)

[Kafka partition 副本同步机制理解](https://blog.csdn.net/lizhitao/article/details/51718185)

[apache kafka技术分享系列](https://blog.csdn.net/lizhitao/article/details/39499283)
